---
title: "SS_Social Determinants of Health"
author: "Joan"
date: "Jan. 25, 2019"
output: html_document
---


```{r}
#install.packages("RODBC")
#remove.packages("dplyr")
#install.packages("plyr")
#install.packages("dplyr")
#install.packages("survival")
#install.packages("Hmisc")
```

## Including Plots

You can also embed plots, for example:

```{r}
library(RODBC)
library(dplyr)
library(ggplot2)
#library(Hmisc)
#library(survival)
#library(dplyr)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r}

myConn <-odbcDriverConnect("Driver=Teradata Database ODBC Driver 16.10;DBCName=servername;Uid=userid;Pwd=password;")

#data <- sqlFetch(myConn,"temp_SDoH_2017_dta")
```

```{r}
# Import the file to R

dta <- read.csv("G:/201902_SDoH/2.Analyze/Personal Folders/Joan/df4.csv",header = TRUE,sep=",",colClasses=c("character","character"))

```

```{r}
dataPath <- "G:/201902_SDoH/2.Analyze/Personal Folders/Joan"
```

```{R}

dta2 <- select(dta, -X, -FIPS_cd, -County_Name, -ST_cd, -County_Name_cat, -ST_cd_cat)
print("done")
```
Now converting the integer to numeric type
```{r}
for(i in c(1:ncol(dta2))) {
    dta2[,i] <- as.numeric(dta2[,i])
}
print("done")

```
```{r}
# Scale
data2 <- data.frame(scale(dta2))
# Verify variance is uniform
plot(sapply(data2, var))


```
Ran an analysis and saved the results. This code now loads the results, instead of re-running the pca model.
```{r}
#x <- prcomp(data2, retx= TRUE)
#round(cor(as.vector(x), as.vector(x$x%*%t(x$rotation))),2)
#save(x,file=paste(dataPath,"x.Rds",sep="/"))
load(file=paste(dataPath,"x.Rds",sep="/"))
plot(x)
```

```{r}
summary(x)
```

```{r}
#biplot(-x$x, -x$rotation, cex=0.6, col=c(1:7))
x$rotation
```
```{r}
plot(x, type="l", cex.lab=1.5, cex.main=1.5)
abline(h=1, lty=3, col="red")
```

```{r}
round(t(x$rotation)%*%x$rotation,2)
```
```{r}
comp <- data.frame(x$x[,1:26])
#plot(comp, pch=16, col=rgb(0,0,0,0.5))
comp
```

```{r}
x.var = x$sdev^2
pve = x.var/sum(x.var)
pve
```

```{r}
plot(pve, xlab="principal component", ylab="Proportion of Variance Explained", ylim=c(0,1), type='b')
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", ylim=c(0,1), type='b')
```

```{r}
#x$rotation
```
Now have to determine the appropriate number of clusters-- will use within sum of squares to determine optimal number
```{r}
# Determine number of clusters
wss <- (nrow(dta2)-1)*sum(apply(dta2,2,var))
for (i in 2:10) wss[i] <- sum(kmeans(dta2,
                                     centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Number of Clusters",
     ylab="Within groups sum of squares")
```
This will list the within in sum of squares for k clusters
```{r}
zz <- cbind(seq(1:30),wss)
#wss1 <- as.data.frame(wss)
#wss1
zz
```
##1. going to look at 8 clusters
```{r}
# apply k-means with k=8
#k <- kmeans(comp, 8, nstart=100)
#save(k,file=paste(dataPath,"k.Rds",sep="/"))
load(file=paste(dataPath,"k_clusters.Rds",sep="/"))

library(RColorBrewer)
library(scales)
#palette(alpha(brewer.pal(9,'Set1'), 0.5))
#plot(comp, col=k$clust, pch=16)



```

```{r}
require(rgl)
plot3d(comp$PC1, comp$PC2, comp$PC3, col=k$clust)
plot3d(comp$PC1, comp$PC3, comp$PC4, col=k$clust)

```
```{r}
#cluster sizes
sort(table(k$cluster))
clust <- names(sort(table(k$cluster)))

```
now looking at the centers of each of the 8 clusters
```{r}
k$centers
```
```{r}
#saving clusters for future use
pca_clusters <- k$cluster
#save(pca_clusters,file=paste(dataPath,"pca_clusters.Rds",sep="/"))
print('done')
```
```{r}
#row.names(dta2)<- dta$County_Name
# First cluster
row.names(dta2$County_Name[k$cluster==clust[1],])
# Second Cluster
row.names(dta2[k$cluster==clust[2],])
# Third Cluster
row.names(dta2[k$cluster==clust[3],])
# Fourth Cluster
row.names(dta2[k$cluster==clust[4],])
```

```{r}
k$centers
```

# Creating a dataset with FIPS and Principal components
```{r}
sdoh_fips <- select(dta, FIPS_cd, ST_cd, County_Name)
```

```{r}
sdoh_pc_1 <- cbind(sdoh_fips, comp)
```
```{r}
head(sdoh_pc_1)
```


```{r}
sdoh_pc_1_clust <- cbind(sdoh_pc_1, pca_clusters)

```


### Merge orginal dataset with pcs and clusters

```{r}
dta1 <- dta
for(i in c(5:ncol(dta))) {
    dta1[,i] <- as.numeric(dta[,i])
}
print("done")

```

```{r}
all_dta <- cbind(dta1, comp, pca_clusters)
```

```{r}
blue <- function(x,y){
  var1 <- mean(x[all_dta$pca_clusters==y])
  result <- paste("mean for cluster ",y,":", var1)
  return(result)
}

blue(all_dta$Median_HH_Income_2017, 5 )
```
```{r}
e = function(expr) eval(parse(text=expr))

varnames<- c("Median_HH_Income_2017", "Total_Pop_2017", "Rural_pcnt_2017", "HS_Grad_pcnt_2017","Obese_pcnt_2017","PCP_Rate_per100K_2017", "Some_College_pcnt_2017")
q <- (seq(1:8))

for (var in varnames){
  for (j in q){
    pp <- paste("all_dta$",var,sep="")
    a <- blue(e(pp),j)
    print(paste(var,"|",a))
    }
}

```
```{r}
#all_dta$County_Name[all_dta$pca_clusters==6]

v <-select(all_dta, FIPS_cd, ST_cd, County_Name, pca_clusters)
#v2 <- filter(v, County_Name=="Philadelphia")
v2 <- filter(v, pca_clusters==5)

v2
```

## after some eda, it looks like 8 clusters might not be optimal due to the imbalanced clusters-- will try 6 clusters

```{r}
# apply k-means with k=6
#k2 <- kmeans(comp, 6, nstart=100)
#save(k2,file=paste(dataPath,"k2.Rds",sep="/"))
load(file=paste(dataPath,"k2.Rds",sep="/"))

library(RColorBrewer)
library(scales)
#palette(alpha(brewer.pal(9,'Set1'), 0.5))
#plot(comp, col=k$clust, pch=16)

```

```{r}
require(rgl)
plot3d(comp$PC1, comp$PC2, comp$PC3, col=k2$clust)
plot3d(comp$PC1, comp$PC3, comp$PC4, col=k2$clust)

```
```{r}
#cluster sizes
sort(table(k2$cluster))
clust <- names(sort(table(k2$cluster)))

```

```{r}
k2$centers
```
```{r}
#saving clusters for future use
pca_clusters2 <- k2$cluster
#save(pca_clusters2,file=paste(dataPath,"pca_clusters2.Rds",sep="/"))
print('done')
```

### Merge orginal dataset with pcs and clusters

```{r}
dta1 <- dta
for(i in c(5:ncol(dta))) {
    dta1[,i] <- as.numeric(dta[,i])
}
print("done")

```

```{r}
all_dta2 <- cbind(dta1, comp, pca_clusters2)
```

```{r}
blue <- function(x,y){
  var1 <- mean(x[all_dta2$pca_clusters==y])
  result <- paste("mean for cluster ",y,":", var1)
  return(result)
}

blue(all_dta2$Median_HH_Income_2017, 5 )
```
```{r}
e = function(expr) eval(parse(text=expr))

varnames<- c("Median_HH_Income_2017", "Total_Pop_2017", "Rural_pcnt_2017", "HS_Grad_pcnt_2017","Obese_pcnt_2017","PCP_Rate_per100K_2017", "Some_College_pcnt_2017")
q <- (seq(1:6))

for (var in varnames){
  for (j in q){
    pp <- paste("all_dta2$",var,sep="")
    a <- blue(e(pp),j)
    print(paste(var,"|",a))
    }
}

```
```{r}
#all_dta$County_Name[all_dta$pca_clusters==6]

v <-select(all_dta2, FIPS_cd, ST_cd, County_Name, pca_clusters2)
#v2 <- filter(v, pca_clusters2==6)
v2 <- filter(v, FIPS_cd==1003)
v2
```


```{r}
sdoh_pc_2_clust <- cbind(sdoh_pc_1, pca_clusters2)

```


##3. 5 clusters
After FURTHER eda, it looks like with 6 clusters, some clusters are not that meaningful; will try 5 clusters

```{r}
# apply k-means with k=5
#k5 <- kmeans(comp, 5, nstart=100)
#save(k5,file=paste(dataPath,"k5_clusters.Rds",sep="/"))
load(file=paste(dataPath,"k5_clusters.Rds",sep="/"))

library(RColorBrewer)
library(scales)
#palette(alpha(brewer.pal(9,'Set1'), 0.5))
#plot(comp, col=k$clust, pch=16)

```

```{r}
require(rgl)
plot3d(comp$PC1, comp$PC2, comp$PC3, col=k5$clust)
#plot3d(comp$PC1, comp$PC3, comp$PC4, col=k5$clust)

```
```{r}
#cluster sizes
sort(table(k5$cluster))
clust <- names(sort(table(k5$cluster)))

```

```{r}
k5$centers
```
```{r}
#saving clusters for future use
pca_clusters5 <- k5$cluster
#save(pca_clusters5,file=paste(dataPath,"pca_clusters5.Rds",sep="/"))
load(file=paste(dataPath,"pca_clusters5.Rds",sep="/"))
print('done')
```

### Merge orginal dataset with pcs and clusters

```{r}
dta1 <- dta
for(i in c(5:ncol(dta))) {
    dta1[,i] <- as.numeric(dta[,i])
}
print("done")

```

```{r}
all_dta5 <- cbind(dta1, comp, pca_clusters5)
```

```{r}
blue <- function(x,y){
  var1 <- mean(x[all_dta5$pca_clusters==y])
  result <- paste("mean for cluster ",y,":", var1)
  return(result)
}

blue(all_dta5$Median_HH_Income_2017, 5 )
```
```{r}
e = function(expr) eval(parse(text=expr))

varnames<- c("Median_HH_Income_2017", "Total_Pop_2017", "Rural_pcnt_2017", "HS_Grad_pcnt_2017","Obese_pcnt_2017","PCP_Rate_per100K_2017", "Some_College_pcnt_2017")

varnames2 <- c("Total_Pop_2017",
"Younger18_pcnt_2017",
"Older65_pcnt_2017",
"Female_pcnt_2017",
"African_American_pcnt_2017",
"Native_American_pcnt_2017",
"Asian_American_pcnt_2017",
"Hawaiian_Pacific_pcnt_2017",
"Hispanic_American_pcnt_2017",
"White_pcnt_2017",
"NonProf_English_pcnt_2017",
"Rural_pcnt_2017",
"Median_HH_Income_2017",
"HS_Grad_pcnt_2017",
"Some_College_pcnt_2017",
"Unemployed_pcnt_2017",
"Child_Proverty_pcnt_2017",
"Violent_Crime_per100K_2017",
"YPLL_per100K_2017",
"FairPoor_Health_pcnt_2017",
"PH_Unhlthy_DAYSperMth_2017"
)
q <- (seq(1:5))

for (var in varnames2){
  for (j in q){
    pp <- paste("all_dta5$",var,sep="")
    a <- blue(e(pp),j)
    print(paste(var,"|",a))
    }
}

```
```{r}
#all_dta$County_Name[all_dta$pca_clusters==6]

v <-select(all_dta2, FIPS_cd, ST_cd, County_Name, pca_clusters5)
#v2 <- filter(v, pca_clusters2==6)
v2 <- filter(v, County_Name=="Philadelphia")
v2
```


```{r}
sdoh_pc_5_clust <- cbind(sdoh_pc_1, pca_clusters5)
```

##4. 3 clusters
let's just explore 3 clusters
```{r}
# apply k-means with k=3
#k3 <- kmeans(comp, 3, nstart=100)
#save(k3,file=paste(dataPath,"k3_clusters.Rds",sep="/"))
load(file=paste(dataPath,"k3_clusters.Rds",sep="/"))

library(RColorBrewer)
library(scales)
#palette(alpha(brewer.pal(9,'Set1'), 0.5))
#plot(comp, col=k$clust, pch=16)

```

```{r}
require(rgl)
plot3d(comp$PC1, comp$PC2, comp$PC3, col=k3$clust)
#plot3d(comp$PC1, comp$PC3, comp$PC4, col=k5$clust)

```
```{r}
#cluster sizes
sort(table(k3$cluster))
clust <- names(sort(table(k3$cluster)))

```

```{r}
k3$centers
```
```{r}
#saving clusters for future use
pca_clusters3 <- k3$cluster
#save(pca_clusters5,file=paste(dataPath,"pca_clusters5.Rds",sep="/"))
#load(file=paste(dataPath,"pca_clusters5.Rds",sep="/"))
print('done')
```

### Merge orginal dataset with pcs and clusters

```{r}
dta1 <- dta
for(i in c(5:ncol(dta))) {
    dta1[,i] <- as.numeric(dta[,i])
}
print("done")

```

```{r}
all_dta3 <- cbind(dta1, comp, pca_clusters3)
```

```{r}
blue <- function(x,y){
  var1 <- mean(x[all_dta3$pca_clusters==y])
  result <- paste("mean for cluster ",y,":", var1)
  return(result)
}

blue(all_dta3$Median_HH_Income_2017, 3 )
```
```{r}
e = function(expr) eval(parse(text=expr))

varnames<- c("Median_HH_Income_2017", "Total_Pop_2017", "Rural_pcnt_2017", "HS_Grad_pcnt_2017","Obese_pcnt_2017","PCP_Rate_per100K_2017", "Some_College_pcnt_2017")
q <- (seq(1:3))

for (var in varnames){
  for (j in q){
    pp <- paste("all_dta3$",var,sep="")
    a <- blue(e(pp),j)
    print(paste(var,"|",a))
    }
}

```
```{r}

v <-select(all_dta2, FIPS_cd, ST_cd, County_Name, pca_clusters3)
#v2 <- filter(v, pca_clusters2==6)
v2 <- filter(v, County_Name=="Philadelphia")
v2
```


### move the sdoh pc data to Teradata database
```{r}
#save(sdoh_pc_2_clust,file=paste(dataPath,"sdoh_pc_2_clust.Rds",sep="/"))

load(file=paste(dataPath,"sdoh_pc_5_clust.Rds",sep="/"))

print('done')
```
```{r}
sqlSave(myConn,sdoh_pc_5_clust,tablename="CA_HET.temp_sdoh_pcs",append = TRUE, rownames = FALSE, colnames=FALSE,verbose = TRUE,safer=TRUE)
print('done')
```

```{r}
sqlSave(myConn,sdoh_pc_1,tablename="temp_sdoh_pcs_clusters",append = TRUE, rownames = FALSE, colnames=FALSE,verbose = TRUE,safer=TRUE)
```

